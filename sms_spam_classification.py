# -*- coding: utf-8 -*-
"""SMS Spam Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1blKT1BS3kssTrx5AUtRVoHAYB91LlR48

**Context**

The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. 
It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam.

**Objective**

To classify the messages as Spam or Ham using NLP.

<h1>Importing Libraries</h1>
"""

import pandas as pd
import numpy as np
import nltk
nltk.download("stopwords")

"""<h1>Loading Data</h1>"""

data = pd.read_csv('spam.csv', encoding='Latin-1')

data.head()

data = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)

data.head()

data.rename(columns= {"v1":"label", "v2":"message"}, inplace=True)

data.head()

"""<h1>Handling Categorical Data</h1>"""

data = pd.get_dummies(data, columns=['label'])

data.head()

data['label_ham'].value_counts()

data.info()

data['count'] = 0
for i in np.arange(0, len(data.message)):
  data.loc[i, 'count'] = len(data.loc[i, 'message'])

data.head()

data.describe()

"""<h1>Processing Message</h1>"""

data['message'][0]

"""**Preparing Word Vector Corpus**"""

corpus = []

"""**Using Porter Stemmer**"""

from nltk.stem.porter import PorterStemmer
import re
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer

ps = PorterStemmer()

for i in range(0, 5572):
  #regular expressions
  msg = data['message'][i]
  #deal with email addresses
  msg = re.sub('\b[\w\-.]+?@\w+?\.\w{2,4}\b', 'emailaddr', data['message'][i])
  #urls
  msg = re.sub('(http[s]?\S+)|(\w+\.[A-Za-z]{2,4}\S*)', 'httpaddr', data['message'][i])
  #money symbols
  msg = re.sub('([A-Z]{3}|[A-Z]?[\$€¥])?\s?(\d{1,3}((,\d{1,3})+)?(.\d{1,3})?(.\d{1,3})?(,\d{1,3})?)', 'moneysymb', data['message'][i])
  #phone numbers
  msg = re.sub('\b(\+\d{1,2}\s)?\d?[\-(.]?\d{3}\)?[\s.-]?\d{3}[\s.-]?\d{4}\b', 'phonenumbr', data['message'][i])
  #numbers
  msg = re.sub('\d+(\.\d+)?', 'numbr', data['message'][i])

  #Removing punctuations
  msg = re.sub('[^\w\d\s]', ' ', data['message'][i])
  if i==0:
    print("\t\t\t\t Message", i)

  if i==0:
    print("\n After Regular Expression - Message ", i, " : ", msg)

  #Each Word to lowercase
  msg = msg.lower()
  if i==0:
    print("\n Lower case Message ", i, " : ", msg)
  
  #Splitting words 
  msg = msg.split()    
  if i==0:
    print("\n After Splitting Message ", i, " : ", msg)
    
  #Stemming with PorterStemmer handling Stop Words
  msg = [ps.stem(word) for word in msg if not word in set(stopwords.words('english'))]
  if i==0:
    print("\n After Stemming Message ", i, " : ", msg)
    
  # preparing Messages with Remaining Tokens
  msg = ' '.join(msg)
  if i==0:
    print("\n Final Prepared Message ", i, " : ", msg, "\n\n")
    
  # Preparing WordVector Corpus
  corpus.append(msg)

"""<h1>Preparing Vectors for Each Message</h1>"""

cv = CountVectorizer()

cv

#converting messages to numeric form
data_input = cv.fit_transform(corpus).toarray()

data_input[0]

data_input

data_input.shape

"""<h1>Applying Classification</h1>

> 

*   **Input: Prepared Sparse Matrix/Vectors for Each Message**
*   **Output: Label i.e. Spam or Ham**




"""

data.head()

data_output = data['label_ham']

data_output.value_counts()

"""**Data Splitting**"""

from sklearn.model_selection import train_test_split

train_x, test_x, train_y, test_y = train_test_split(data_input, data_output, test_size=0.20, random_state=0)

"""<h1>ML Model</h1>"""

from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn import tree
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

"""**Training**"""

nvb = GaussianNB()
nvb.fit(train_x, train_y)

dec = tree.DecisionTreeClassifier()
dec.fit(train_x, train_y)

rf = RandomForestClassifier(n_estimators=200)
rf.fit(train_x, train_y)

"""**Predictions**"""

pred_nvb = nvb.predict(test_x)
pred_dec = dec.predict(test_x)
pred_rf = rf.predict(test_x)

print ("Accuracy : %0.5f \n\n" % accuracy_score(test_y, pred_nvb))
print (classification_report(test_y, pred_nvb))

print ("Accuracy : %0.5f \n\n" % accuracy_score(test_y, pred_dec))
print (classification_report(test_y, pred_dec))

print ("Accuracy : %0.5f \n\n" % accuracy_score(test_y, pred_rf))
print (classification_report(test_y, pred_rf))

"""<h1>Final Accuracy</h1>


> 

*   **Random Forest : 97.220%**
*   **Decision Tree : 97.040%**
*   **GaussianNB : 87.085%**






"""

